
import warnings
warnings.filterwarnings("ignore")
import os
import pandas as pd
import sys
from minio_connect import connect
import uploadData
import downloadData

#ENVS
exclude_y= os.environ.get('exclude_y',"n")
num_h_bb = int(os.environ.get('nHoursBeforeSleep', 12))


working_dir="/app"
uploadfile= "real.csv"
bucket_name='data'
#CONNECTIONG MINIO
minio_client = connect()
if downloadData.download_files_excel(minio_client, working_dir, bucket_name, reset=True) == False:
    print("download failed")
    sys.exit(-1)

# Function to process each Excel file
def process_excel(file_path):
    dfH = pd.read_excel(file_path, sheet_name="Hourly", usecols=["Subject", "METs", "Date", "Hour"])
    dfS = pd.read_excel(file_path, sheet_name="Sleep Scores", usecols=["Sleep Fragmentation Index", "In Bed Date", "In Bed Time", "Out Bed Date", "Out Bed Time"])
    dfH['DateTime'] = pd.to_datetime(dfH['Date'] + ' ' + dfH['Hour'], format='%d/%m/%Y %H:%M')
    dfH.drop(columns=['Date', 'Hour'], inplace=True)
    #in some excel files there are missmatching types for dates
    if pd.api.types.is_datetime64_any_dtype(dfS['In Bed Date']):
        in_bed_date = dfS['In Bed Date'].dt.strftime('%d/%m/%Y')
        out_bed_date = dfS['Out Bed Date'].dt.strftime('%d/%m/%Y')
    else:
        in_bed_date = dfS['In Bed Date']
        out_bed_date = dfS['Out Bed Date']
    
    in_bed_time_str = dfS['In Bed Time'].astype(str)
    out_bed_time_str = dfS['Out Bed Time'].astype(str)
    dfS['In Bed DateTime'] = pd.to_datetime(in_bed_date + ' ' + in_bed_time_str, format='%d/%m/%Y %H:%M:%S')
    dfS['Out Bed DateTime'] = pd.to_datetime(out_bed_date + ' ' + out_bed_time_str, format='%d/%m/%Y %H:%M:%S')
    dfS.drop(columns=['In Bed Date', 'In Bed Time', 'Out Bed Date', 'Out Bed Time'], inplace=True)
        
    # Create an empty list to store results
    result_rows = []
    dfS["Sleep Fragmentation Index"]=dfS["Sleep Fragmentation Index"].fillna(0)
    for index_s, row_s in dfS.iterrows():
        selected_rows_dfH = dfH[(dfH['DateTime'] < row_s['In Bed DateTime']) & (dfH['DateTime'] >= row_s['In Bed DateTime'] - pd.Timedelta(hours=num_h_bb))]
        selected_rows_dfH = selected_rows_dfH.iloc[::-1]
        mets = []
        row_s['Sleep Fragmentation Index']=row_s['Sleep Fragmentation Index']
        if index_s == 0:
            prev_out_bed = row_s['Out Bed DateTime']
            if not selected_rows_dfH.empty:
                delta = row_s['In Bed DateTime']-selected_rows_dfH.iloc[-1]['DateTime']
            else:
                delta = pd.Timedelta(hours=0)
        else:
            if not selected_rows_dfH.empty: 
                if len(selected_rows_dfH) > 1:  # Check if there are at least two rows for comparison
                    delta = selected_rows_dfH.iloc[0]['DateTime'] - prev_out_bed
                    
                else:
                    delta = pd.Timedelta(hours=1)
            else:
                delta = pd.Timedelta(hours=0) 
    
            prev_out_bed = row_s['Out Bed DateTime']
        i=0
        if delta.total_seconds()/3600>1:
            for _, row_h in selected_rows_dfH.iterrows():
                if i < int(delta.total_seconds() / 3600):
                    mets_value = row_h['METs']
                else:
                    mets_value = 1
                mets.append(mets_value)
                i+=1
    
            for i in range(i, num_h_bb):
                mets.append(1)
        
            result_rows.append({
                'SFI': row_s["Sleep Fragmentation Index"],
                **{'METs ' + str(i): mets[i] for i in range(0, num_h_bb)}
            })
        else:
            if len(result_rows)>0:
                result_rows[-1]['SFI']= max(result_rows[-1]['SFI'], row_s['Sleep Fragmentation Index'])
                    
        # Remove selected rows from dfH
        dfH = dfH[dfH['DateTime'] >= row_s['Out Bed DateTime']]
    return pd.DataFrame(result_rows)

folder_path = '/app'
esiste=False
results = []
for file in os.listdir(folder_path):
    if file.endswith('.xlsx'):
        file_path = os.path.join(folder_path, file)
        df = process_excel(file_path)
        results.append(df)
        os.remove(file_path)
        esiste=True
if not esiste:
    print("ERROR: Conversion failed, no matching found, check existance on minio, looking for:",patterns)
    sys.exit(-1)
#append df togheter, could iterate on rjc joindf
result_df = pd.concat(results, ignore_index=True)

if exclude_y!="n":  #exclude dependent var On 
    result_df.drop(columns=["SFI"])
#custom header, for auto concatenation with index headers generated by other services
custom = [f"{i}" for i in range(0,num_h_bb+1)]

result_df.to_csv("/app/real.csv", index=False, header=custom)
uploadData.upload_file_to_minio(minio_client,working_dir+"/"+uploadfile, bucket_name, uploadfile)

sys.exit(0)
